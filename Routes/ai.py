# routers/ai.py

import os
import json
from typing import List

import httpx
from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel
from sqlalchemy.orm import Session

from db.sessions import get_db
from db.models import Exam, ExamQuestion, ExamSource

HF_API_TOKEN = os.getenv("HF_API_TOKEN")

router = APIRouter(prefix="/ai", tags=["ai"])

HF_URL = "https://router.huggingface.co/v1/chat/completions"
MODEL_NAME = "meta-llama/Llama-3.1-8B-Instruct"


# ---------- Schemas ----------

class SummarizeRequest(BaseModel):
    text: str


class QuizRequest(BaseModel):
    text: str
    num_questions: int = 10  # you can change default


class QuizQuestion(BaseModel):
    question: str
    options: List[str]
    correct_index: int  # 0â€“3


# ---------- Summarize Endpoint ----------

@router.post("/summarize")
async def summarize_text(request: SummarizeRequest):
    if not HF_API_TOKEN:
        raise HTTPException(status_code=500, detail="HF_API_TOKEN not set")

    headers = {
        "Authorization": f"Bearer {HF_API_TOKEN}",
        "Content-Type": "application/json",
    }

    payload = {
        "model": MODEL_NAME,
        "messages": [
            {
                "role": "system",
                "content": "You are a helpful study assistant. Summarize clearly and concisely.",
            },
            {
                "role": "user",
                "content": f"Summarize the following text in 5 short bullet points:\n\n{request.text}",
            },
        ],
        "temperature": 0.4,
        "max_tokens": 256,
    }

    async with httpx.AsyncClient(timeout=60.0) as client:
        resp = await client.post(HF_URL, headers=headers, json=payload)

    if resp.status_code != 200:
        raise HTTPException(
            status_code=resp.status_code,
            detail=f"HuggingFace error: {resp.text}",
        )

    data = resp.json()
    try:
        summary = data["choices"][0]["message"]["content"]
    except Exception:
        raise HTTPException(500, "Bad response format from HuggingFace")

    return {"summary": summary}


# ---------- Quiz Generation + SAVE to DB ----------

@router.post("/generate-quiz")
async def generate_quiz_and_save(
    request: QuizRequest,
    user_id: int,
    db: Session = Depends(get_db),
):
    """
    1. Generate MCQs from text using Llama 3.1.
    2. Save Exam + ExamQuestions to DB.
    3. Return exam_id + questions.
    """
    if not HF_API_TOKEN:
        raise HTTPException(status_code=500, detail="HF_API_TOKEN not set")

    headers = {
        "Authorization": f"Bearer {HF_API_TOKEN}",
        "Content-Type": "application/json",
    }

    user_prompt = f"""
Generate {request.num_questions} multiple-choice questions (MCQs) based on the following text.

Return ONLY a JSON array (no backticks, no markdown, no explanation) where each element has:
- "question": string
- "options": array of exactly 4 short answer strings
- "correct_index": integer 0-3 indicating which option is correct.

Text:
{request.text}
"""

    payload = {
        "model": MODEL_NAME,
        "messages": [
            {
                "role": "system",
                "content": (
                    "You are an exam generator for students. You ALWAYS follow the requested JSON schema "
                    "exactly and never add extra text or formatting."
                ),
            },
            {"role": "user", "content": user_prompt},
        ],
        "temperature": 0.3,
        "max_tokens": 1024,
    }

    # ---- 1) Call HF ----
    async with httpx.AsyncClient(timeout=90.0) as client:
        resp = await client.post(HF_URL, headers=headers, json=payload)

    if resp.status_code != 200:
        raise HTTPException(
            status_code=resp.status_code,
            detail=f"HuggingFace error: {resp.text}",
        )

    data = resp.json()

    try:
        raw_content = data["choices"][0]["message"]["content"]
    except Exception:
        raise HTTPException(500, "Bad response format from HuggingFace")

    try:
        items = json.loads(raw_content)
    except json.JSONDecodeError:
        raise HTTPException(
            500,
            detail="Model did not return valid JSON. Try again with shorter text or fewer questions.",
        )

    if not isinstance(items, list) or not items:
        raise HTTPException(500, detail="No questions generated by the model.")

    # ---- 2) Create Exam ----
    exam = Exam(
        user_id=user_id,
        title="AI-Generated Quiz",
        source_type=ExamSource.manual,  # or note/transcript depending on context
        source_id=None,
        grade=None,
    )
    db.add(exam)
    db.commit()
    db.refresh(exam)

    # ---- 3) Create ExamQuestion rows ----
    saved_questions = []

    for idx, item in enumerate(items):
        try:
            question_text = item["question"]
            options = item["options"]
            correct_index = item["correct_index"]

            exam_q = ExamQuestion(
                exam_id=exam.id,
                question=question_text,
                options=options,
                answer_idx=correct_index,
                order=idx,
            )
            db.add(exam_q)
            saved_questions.append(exam_q)
        except Exception:
            # skip malformed items instead of failing everything
            continue

    if not saved_questions:
        db.delete(exam)
        db.commit()
        raise HTTPException(500, detail="No valid questions could be saved to DB.")

    db.commit()
    # refresh to ensure IDs are loaded
    for q in saved_questions:
        db.refresh(q)

    # ---- 4) Return payload for client ----
    return {
        "exam_id": exam.id,
        "title": exam.title,
        "questions": [
            {
                "id": q.id,
                "question": q.question,
                "options": q.options,
                "correct_index": q.answer_idx,
                "order": q.order,
            }
            for q in saved_questions
        ],
    }
