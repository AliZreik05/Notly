# routers/ai.py

import os
import json
from typing import List, Optional

import httpx
from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel
from sqlalchemy.orm import Session

from db.sessions import get_db
from db.models import (
    Exam,
    ExamQuestion,
    ExamSource,
    FlashCardDeck,
    FlashCard,
    SourceType,
)

HF_API_TOKEN = os.getenv("HF_API_TOKEN")

router = APIRouter(prefix="/ai", tags=["ai"])

HF_URL = "https://router.huggingface.co/v1/chat/completions"
MODEL_NAME = "meta-llama/Llama-3.1-8B-Instruct"


# ---------- Schemas ----------

class SummarizeRequest(BaseModel):
    text: str


class QuizRequest(BaseModel):
    text: str
    num_questions: int = 10  # you can change default


class QuizQuestion(BaseModel):
    question: str
    options: List[str]
    correct_index: int  # 0â€“3


class FlashcardAIRequest(BaseModel):
    text: str
    num_cards: int = 20
    title: Optional[str] = None

class FlashcardItem(BaseModel):
    id: int
    front: str
    back: str

class FlashcardDeckOut(BaseModel):
    deck_id: int
    title: str
    cards: List[FlashcardItem]


# ---------- Summarize Endpoint ----------

@router.post("/summarize")
async def summarize_text(request: SummarizeRequest):
    if not HF_API_TOKEN:
        raise HTTPException(status_code=500, detail="HF_API_TOKEN not set")

    headers = {
        "Authorization": f"Bearer {HF_API_TOKEN}",
        "Content-Type": "application/json",
    }

    payload = {
        "model": MODEL_NAME,
        "messages": [
            {
                "role": "system",
                "content": "You are a helpful study assistant. Summarize clearly and concisely.",
            },
            {
                "role": "user",
                "content": f"Summarize the following text in 5 short bullet points:\n\n{request.text}",
            },
        ],
        "temperature": 0.4,
        "max_tokens": 256,
    }

    async with httpx.AsyncClient(timeout=60.0) as client:
        resp = await client.post(HF_URL, headers=headers, json=payload)

    if resp.status_code != 200:
        raise HTTPException(
            status_code=resp.status_code,
            detail=f"HuggingFace error: {resp.text}",
        )

    data = resp.json()
    try:
        summary = data["choices"][0]["message"]["content"]
    except Exception:
        raise HTTPException(500, "Bad response format from HuggingFace")

    return {"summary": summary}


# ---------- Quiz Generation + SAVE to DB ----------

@router.post("/generate-quiz")
async def generate_quiz_and_save(
    request: QuizRequest,
    user_id: int,
    db: Session = Depends(get_db),
):
    """
    1. Generate MCQs from text using Llama 3.1.
    2. Save Exam + ExamQuestions to DB.
    3. Return exam_id + questions.
    """
    if not HF_API_TOKEN:
        raise HTTPException(status_code=500, detail="HF_API_TOKEN not set")

    headers = {
        "Authorization": f"Bearer {HF_API_TOKEN}",
        "Content-Type": "application/json",
    }

    user_prompt = f"""
Generate {request.num_questions} multiple-choice questions (MCQs) based on the following text.

Return ONLY a JSON array (no backticks, no markdown, no explanation) where each element has:
- "question": string
- "options": array of exactly 4 short answer strings
- "correct_index": integer 0-3 indicating which option is correct.

Text:
{request.text}
"""

    payload = {
        "model": MODEL_NAME,
        "messages": [
            {
                "role": "system",
                "content": (
                    "You are an exam generator for students. You ALWAYS follow the requested JSON schema "
                    "exactly and never add extra text or formatting."
                ),
            },
            {"role": "user", "content": user_prompt},
        ],
        "temperature": 0.3,
        "max_tokens": 1024,
    }

    # ---- 1) Call HF ----
    async with httpx.AsyncClient(timeout=90.0) as client:
        resp = await client.post(HF_URL, headers=headers, json=payload)

    if resp.status_code != 200:
        raise HTTPException(
            status_code=resp.status_code,
            detail=f"HuggingFace error: {resp.text}",
        )

    data = resp.json()

    try:
        raw_content = data["choices"][0]["message"]["content"]
    except Exception:
        raise HTTPException(500, "Bad response format from HuggingFace")

    try:
        items = json.loads(raw_content)
    except json.JSONDecodeError:
        raise HTTPException(
            500,
            detail="Model did not return valid JSON. Try again with shorter text or fewer questions.",
        )

    if not isinstance(items, list) or not items:
        raise HTTPException(500, detail="No questions generated by the model.")

    # ---- 2) Create Exam ----
    exam = Exam(
        user_id=user_id,
        title="AI-Generated Quiz",
        source_type=ExamSource.manual,  # or note/transcript depending on context
        source_id=None,
        grade=None,
    )
    db.add(exam)
    db.commit()
    db.refresh(exam)

    # ---- 3) Create ExamQuestion rows ----
    saved_questions = []

    for idx, item in enumerate(items):
        try:
            question_text = item["question"]
            options = item["options"]
            correct_index = item["correct_index"]

            exam_q = ExamQuestion(
                exam_id=exam.id,
                question=question_text,
                options=options,
                answer_idx=correct_index,
                order=idx,
            )
            db.add(exam_q)
            saved_questions.append(exam_q)
        except Exception:
            # skip malformed items instead of failing everything
            continue

    if not saved_questions:
        db.delete(exam)
        db.commit()
        raise HTTPException(500, detail="No valid questions could be saved to DB.")

    db.commit()
    # refresh to ensure IDs are loaded
    for q in saved_questions:
        db.refresh(q)

    # ---- 4) Return payload for client ----
    return {
        "exam_id": exam.id,
        "title": exam.title,
        "questions": [
            {
                "id": q.id,
                "question": q.question,
                "options": q.options,
                "correct_index": q.answer_idx,
                "order": q.order,
            }
            for q in saved_questions
        ],
    }


# ---------- Flashcard Generation + SAVE to DB ----------

@router.post("/generate-flashcards")
async def generate_flashcards_and_save(
    request: FlashcardAIRequest,
    user_id: int,
    db: Session = Depends(get_db),
):
    """
    1. Generate flashcards from text using Llama 3.1.
    2. Save FlashCardDeck + FlashCard rows to DB.
    3. Return deck_id + cards.
    """
    if not HF_API_TOKEN:
        raise HTTPException(status_code=500, detail="HF_API_TOKEN not set")

    headers = {
        "Authorization": f"Bearer {HF_API_TOKEN}",
        "Content-Type": "application/json",
    }

    user_prompt = f"""
Create {request.num_cards} concise study flashcards from the following text.

Return ONLY a JSON array (no backticks, no markdown, no explanation) where each element has:
- "front": short prompt or question (<= 120 characters ideally)
- "back": clear answer/explanation (<= 240 characters ideally)

Text:
{request.text}
"""

    payload = {
        "model": MODEL_NAME,
        "messages": [
            {
                "role": "system",
                "content": (
                    "You are a flashcard generator for students. You ALWAYS follow the requested JSON schema "
                    "exactly and never add extra text or formatting."
                ),
            },
            {"role": "user", "content": user_prompt},
        ],
        "temperature": 0.35,
        "max_tokens": 1024,
    }

    # ---- 1) Call HF ----
    async with httpx.AsyncClient(timeout=90.0) as client:
        resp = await client.post(HF_URL, headers=headers, json=payload)

    if resp.status_code != 200:
        raise HTTPException(
            status_code=resp.status_code,
            detail=f"HuggingFace error: {resp.text}",
        )

    data = resp.json()

    try:
        raw_content = data["choices"][0]["message"]["content"]
    except Exception:
        raise HTTPException(500, "Bad response format from HuggingFace")

    try:
        items = json.loads(raw_content)
    except json.JSONDecodeError:
        raise HTTPException(
            500,
            detail="Model did not return valid JSON. Try again with shorter text or fewer cards.",
        )

    if not isinstance(items, list) or not items:
        raise HTTPException(500, detail="No flashcards generated by the model.")

    # ---- 2) Create FlashcardDeck ----
    deck = FlashCardDeck(
        user_id=user_id,
        title=request.title or "AI Flashcards",
        source_type=SourceType.manual,
        source_id=None,
    )
    db.add(deck)
    db.commit()
    db.refresh(deck)

    # ---- 3) Create FlashCard rows ----
    saved_cards = []
    for item in items:
        try:
            front = item["front"]
            back = item["back"]
            if not front or not back:
                continue

            card = FlashCard(
                set_id=deck.id,
                user_id=user_id,
                prompt=front,
                answer=back,
            )
            db.add(card)
            saved_cards.append(card)
        except Exception:
            continue

    if not saved_cards:
        db.delete(deck)
        db.commit()
        raise HTTPException(500, detail="No valid flashcards could be saved to DB.")

    db.commit()
    for c in saved_cards:
        db.refresh(c)

    # ---- 4) Return payload for client ----
    return {
        "deck_id": deck.id,
        "title": deck.title,
        "cards": [
            {
                "id": c.id,
                "front": c.prompt,
                "back": c.answer,
            }
            for c in saved_cards
        ],
    }


# ---------- Flashcard Fetch Endpoints ----------

@router.get("/flashcards/{deck_id}", response_model=FlashcardDeckOut)
def get_flashcard_deck(deck_id: int, user_id: int, db: Session = Depends(get_db)):
    """
    Fetch a saved flashcard deck (with cards) by deck_id for the given user.
    """
    deck = (
        db.query(FlashCardDeck)
        .filter(FlashCardDeck.id == deck_id, FlashCardDeck.user_id == user_id)
        .first()
    )
    if not deck:
        raise HTTPException(status_code=404, detail="Deck not found for this user")

    cards = (
        db.query(FlashCard)
        .filter(FlashCard.set_id == deck.id)
        .order_by(FlashCard.id.asc())
        .all()
    )

    return FlashcardDeckOut(
        deck_id=deck.id,
        title=deck.title,
        cards=[
            FlashcardItem(
                id=c.id,
                front=c.prompt,
                back=c.answer,
            ) for c in cards
        ],
    )


@router.get("/flashcards", response_model=List[FlashcardDeckOut])
def list_flashcard_decks(user_id: int, db: Session = Depends(get_db)):
    """
    List all flashcard decks (with cards) for the given user.
    """
    decks = db.query(FlashCardDeck).filter(FlashCardDeck.user_id == user_id).all()
    result: List[FlashcardDeckOut] = []

    for deck in decks:
        cards = (
            db.query(FlashCard)
            .filter(FlashCard.set_id == deck.id)
            .order_by(FlashCard.id.asc())
            .all()
        )
        result.append(
            FlashcardDeckOut(
                deck_id=deck.id,
                title=deck.title,
                cards=[
                    FlashcardItem(
                        id=c.id,
                        front=c.prompt,
                        back=c.answer,
                    ) for c in cards
                ],
            )
        )
    return result
